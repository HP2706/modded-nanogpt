numpy
tqdm
torch==2.7.0
huggingface-hub
liger-kernel
wandb<=0.18.7
transformers
adam-mini
transformers
tqdm
hf-transfer
fire
einx
einops
jaxtyping
matplotlib
mcp
#fla @ git+https://github.com/fla-org/flash-linear-attention.git
#transformer_nuggets @ git+https://github.com/drisspg/transformer_nuggets